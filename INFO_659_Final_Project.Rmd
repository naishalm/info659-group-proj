---
title: "INFO-659_Final_Project_Accident_Report_Data"
author: "Rafi Ahmad, Naishal Chauhan, Megan Cunningham, and Jinsu Mathew"
date: "2024-11-02"
output: html_document
---
# Analysis of Crash Report Sampling System (CRSS) 2022 Accident Data 
The analysis of crash data for the years 2022 from the Crash Report Sampling System (CRSS) will be the focus of our study. The primary objective of  this project is to identify key factors contributing to high-severity accidents and provide insights for developing preventive strategies and optimizing emergency response efforts. Through the analysis of the CRSS data, we seek to pinpoint the major patterns and variables that lead to auto accidents, with an emphasis on how the environment, different kinds of vehicles, and driving habits affect collision results. In order to anticipate the severity of injuries and classify collision types according to vehicle involvement and road circumstances, we will investigate both clustering and classification algorithms. The results will help us comprehend collision causes better and provide guidance for enhancing road safety. Additionally, this information will allow emergency responders to better anticipate what staffing, medical, and other resources are needed, where they will be needed, and when. 

We will be using the data provided by the National Highway Traffic Safety Administration’s (NHTSA) Crash Reporting Sampling System (CRSS) - NHTSA File Downloads | NHTSA. Our primary focus will be on the “accident.csv” file, which contains a wide range of accident types caused by various factors, not limited to vehicle-to-vehicle collisions but also covering incidents involving animals, utility problems, and environmental factors such as fallen trees. With attributes like region, type of road, time of day, severity of injuries, presence of alcohol, and other demographic and situational variables, this data offers a comprehensive view of factors surrounding motor vehicle collisions.  

Prior to completing an exploratory data analysis (EDA) to compile the data distribution and spot trends, the data will be reviewed and cleansed to accommodate missing values and outliers. Initial analysis will involve exploring patterns such as accident hotspots, determining the time of day with high frequency of accidents, and exploring the correlation between certain variables (such as substance involvement) and injury severity. By understanding these patterns, the project aims to demonstrate how specific factors increase the likelihood of high severity accidents and highlight opportunities for intervention. 
 
 

## Goals of Project
1. Identify key factors contributing to high-severity accidents
  - Key attributes: type of collision, location of collision, time of day, severity of crash, demographic information, injuries/outcome of crash
2. Determine potential crash preventative strategies
3. Optimize emergency response efforts

## Preliminaries
Load R packages:
```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(caret)
library(xgboost)
library(tidymodels)
library(discrim)
library(ranger)
```

## Set the seed
```{r}
set.seed(20241128)
```

## Specifying Metrics

Setting the metrics we want to calculate: accuracy, precision, sensitivity, specificity, and Cohen's Kappa.

```{r}
sba_metrics = metric_set(accuracy, precision, sensitivity, specificity, kap)
```
## Load the Data
```{r}
accident.data.raw = read_csv("data_files/CRSS2022CSV/accident.csv")

accident.data.raw
```
## Cleanse the data
```{r}
accident.data = accident.data.raw %>%
  mutate(NUM_INJ = ifelse(NUM_INJ>97, NA, NUM_INJ))

accident.data
```

Introducing the variables: 

1. CASENUM: Case number

2. REGIONNAME : Geographic region's name

3. URBANICITYNAME : Describes the level of urbanicity (urban or rural areas)

4. HOUR_IM: represent the hour of the incident

5. RELJCT2_IMNAME : Describes the relation to the junction for the second incident or vehicle (e.g., “At Intersection”)

6. LGTCON_IMNAME: Describes light conditions

7. WEATHR_IMNAME: Describes weather conditions 

8. MAXSEV_IM: Code indicating the maximum severity level of the incident

9. MAXSEV_IMNAME: Descriptive name for MAXSEV_IM

10. NO_INJ_IM : Represents the number of injuries 

11. ALCHL_IMNAME: Describes alcohol involvement 

12. MONTHNAME: Month of the incident 


Cleaning the data: 

```{r}
# Replace missing values in categorical columns with "Unknown"
accident_data = accident.data.raw %>%
  mutate_if(is.character, ~replace(., is.na(.), "Unknown"))

# Replace missing values in numeric columns with the median
accident_data = accident_data %>%
  mutate_if(is.numeric, ~replace(., is.na(.), median(., na.rm = TRUE)))


```

```{r}
cleaned_data = accident_data %>%
  select(CASENUM, REGIONNAME, URBANICITYNAME, MONTHNAME, HOUR_IM, RELJCT2_IMNAME, LGTCON_IMNAME, WEATHR_IMNAME, MAXSEV_IM, MAXSEV_IMNAME, NO_INJ_IM, ALCHL_IMNAME)
```

```{r}
# Rename columns for clarity
renamed_accident_data = cleaned_data %>%
  rename(
    case_number = CASENUM,
    region_name = REGIONNAME, 
    urbancity_name = URBANICITYNAME, 
    month_name = MONTHNAME,
    hour = HOUR_IM, 
    junction_name = RELJCT2_IMNAME, 
    light_condition = LGTCON_IMNAME, 
    weather_name = WEATHR_IMNAME, 
    max_severity_level = MAXSEV_IM, 
    max_severity_des = MAXSEV_IMNAME, 
    injur_no = NO_INJ_IM,
    alcohol_involved = ALCHL_IMNAME
  )
renamed_accident_data
```

#we can check for in which month the accidents are high
#where accidents are high or in what region the accidents are high - is it in urban or rural areas
#the weather condtion 
#how severity the injury level 
#the time at which the accident occur: check for the most common time 
#the number of injuries
#is there any alcohol involvement 


Removing any duplicates 
```{r}
renamed_accident_data =  renamed_accident_data %>% distinct()
renamed_accident_data
```
Truncating Region Names
```{r}
accident.data = renamed_accident_data %>%
  mutate(region_name = str_split(region_name, "\\(", simplify = T)[,1])

accident.data
```


## Load Person Data

The person data file includes list of individuals involved in an accident and various factors including - age, sex, their involvement in the accident (driver, passenger, etc.), whether they were injuried and the severity of their injuries, and if they were transported to a hospital.
```{r}
person.data.raw = read_csv("data_files/CRSS2022CSV/person.csv")

person.data.raw
```




## Cleanse Person Data

```{r}
# Replace missing values in categorical columns with "Unknown"
person.data.na.filter = person.data.raw %>%
  mutate_if(is.character, ~replace(., is.na(.), "Unknown"))

# Replace missing values in numeric columns with the median
person.data.na.filter = person.data.na.filter %>%
  mutate_if(is.numeric, ~replace(., is.na(.), median(., na.rm = TRUE)))

person.data.na.filter
```


Select the variables we want and use code-book to reduce categories to simplify data analysis:
- Unique identifies for joins: CASENUM and PER_NO
- Age of person involved: AGE_IM renamed to AGE_OF_PERSON
- Sex of person involved: SEX_IMNAME renamed to SEX_OF_PERSON
- Whether the person was the Driver, Passenger, Other - Occupant, or Other - Non-Occupant - PER_TYP/PER_TYPNAME renamed to PERSON_INVOLVED_TYPE.
- The injury severity - INJSEV_IMNAME renamed to INJURY_SEVERITY - and reduced to: No Known Injury, Injury - Severity Minor or Unknown, Serious Injury, Fatal Injury, or Other - Injury or Fatality not From Crash
- Whether the person's airbag deployed: AIR_BAGNAME renamed to AIRBAG_DEPLOYMENT
- Whether the person was transported to the hospital - HOSPITALNAME renamed to HOSPITAL_TRANSPORT_STATUS
- Whether a rollover occured in the accident - ROLLOVERNAME renamed to ROLLOVER_OCCURENCE
- Whether a fire was related to the accident - FIRE_EXPNAME renamed to FIRE_RELATED_CRASH

```{r}
person.data = person.data.na.filter %>%
  select(CASENUM, PER_NO, AGE_IM, SEX_IMNAME, PER_TYP, PER_TYPNAME, INJSEV_IM, INJSEV_IMNAME, 
         AIR_BAG, AIR_BAGNAME, EJECT_IM, EJECT_IMNAME, HOSPITAL, HOSPITALNAME, ROLLOVER, ROLLOVERNAME, FIRE_EXP, FIRE_EXPNAME) %>%
    mutate(PER_TYPNAME=ifelse(person.data.na.filter$PER_TYP == 1, "Driver", 
                              ifelse(person.data.na.filter$PER_TYP == 2, "Passenger",
                                     ifelse(person.data.na.filter$PER_TYP == 9 | person.data.na.filter$PER_TYP %in% c(3,4), "Other - Occupant",
                                     "Other - Non-occupant")))) %>%
    mutate(INJSEV_IMNAME=ifelse(person.data.na.filter$INJSEV_IM == 0 | person.data.na.filter$INJSEV_IM == 9, "No Known Injury", 
                              ifelse(person.data.na.filter$INJSEV_IM == 5 | person.data.na.filter$INJSEV_IM %in% c(1,2), "Injury - Severity Minor or Unknown",
                                     ifelse(person.data.na.filter$INJSEV_IM == 3, "Serious Injury",
                                            ifelse(person.data.na.filter$INJSEV_IM == 4, "Fatal Injury", "Other - Injury or Fatality not From Crash"))))) %>%
    mutate(AIR_BAGNAME=ifelse(person.data.na.filter$AIR_BAG %in% c(1,9),
                              "Deployed", 
                              ifelse(person.data.na.filter$AIR_BAG == 20 | person.data.na.filter$AIR_BAG == 28,
                                     "Not Deployed", "Deployment Unknown"))) %>%
    mutate(EJECT_IMNAME=ifelse(person.data.na.filter$EJECT_IM %in% c(1,3),
                              "Ejected", 
                              ifelse(person.data.na.filter$EJECT_IM == 0,
                                     "Not Ejected", "Ejection Unknown"))) %>%
    mutate(HOSPITALNAME=ifelse(person.data.na.filter$HOSPITAL == 0,
                                     "No Hospital Transport",
                                 ifelse(person.data.na.filter$HOSPITAL %in% c(8,9),
                                     "Hospital Transport Status Unknown", "Transported to Hospital"))) %>%
    mutate(ROLLOVERNAME=ifelse(person.data.na.filter$ROLLOVER %in% c(1,3) | person.data.na.filter$ROLLOVER == 9,
                                     "Rollover Occured", ROLLOVERNAME)) %>%
    rename("AGE_OF_PERSON" = AGE_IM) %>%
    rename("PERSON_INVOLVED_TYPE" = PER_TYPNAME) %>%
    rename("SEX_OF_PERSON" = SEX_IMNAME) %>%
    rename("INJURY_SEVERITY" = INJSEV_IMNAME) %>%
    rename("AIRBAG_DEPLOYMENT" = AIR_BAGNAME) %>%
    rename("PERSON_EJECTED" = EJECT_IMNAME) %>%
    rename("HOSPITAL_TRANSPORT_STATUS" = HOSPITALNAME) %>%
    rename("ROLLOVER_OCCURENCE" = ROLLOVERNAME) %>%
    rename("FIRE_RELATED_CRASH" = FIRE_EXPNAME)

person.data
```



## Let's look at some distributions

```{r}
accident.data
```

```{r}
summary(accident.data$injur_no)
```

```{r}
ggplot(accident.data) +
  aes(x=injur_no, na.rm = TRUE) +
  geom_histogram(binwidth=1,col="blue", fill="lightblue")+
  geom_vline(xintercept = mean(accident.data$injur_no, na.rm=TRUE),
             color='black') +
  geom_vline(xintercept = median(accident.data$injur_no, na.rm=TRUE),
             color='red')
```
```{r}
ggplot(accident.data, aes(y=max_severity_des)) + 
  geom_bar(stat="count", na.rm = TRUE)+ 
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5))
```

```{r}
ggplot(accident.data) +
  aes(x=weather_name, y=injur_no, fill=max_severity_des) +
  geom_col() +
  scale_fill_brewer(palette="Set1") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) 
```


```{r}
ggplot(accident.data) +
  aes(x=alcohol_involved) +
  geom_bar() 
```


## Join the Data through CaseNum

```{r}
accident.join = person.data %>%
  left_join(., accident.data, by=join_by(CASENUM==case_number)) %>%
  filter(HOSPITAL_TRANSPORT_STATUS != "Hospital Transport Status Unknown")

accident.join
```

## Create Outcome column and select inputs for outcome related to hospital transport

```{r}
accident.join = accident.join %>%
  mutate(Outcome = as.factor(if_else(HOSPITAL_TRANSPORT_STATUS == "Transported to Hospital",
                                     "Transported to Hospital", "No Hospital Transport"))) %>%
  mutate(SEX_OF_PERSON = as.factor(SEX_OF_PERSON)) %>%
  mutate(PERSON_INVOLVED_TYPE = as.factor(PERSON_INVOLVED_TYPE)) %>%
  mutate(AIRBAG_DEPLOYMENT = as.factor(AIRBAG_DEPLOYMENT)) %>%
  mutate(PERSON_EJECTED = as.factor(PERSON_EJECTED)) %>%
  mutate(ROLLOVER_OCCURENCE = as.factor(ROLLOVER_OCCURENCE)) %>%
  mutate(FIRE_RELATED_CRASH = as.factor(FIRE_RELATED_CRASH)) %>%
  mutate(region_name = as.factor(region_name)) %>%
  mutate(urbancity_name = as.factor(urbancity_name)) %>%
  mutate(month_name = as.factor(month_name)) %>%
  mutate(light_condition = as.factor(light_condition)) %>%
  mutate(weather_name = as.factor(weather_name))
  
accident.join.filtered = accident.join %>%
  select(AGE_OF_PERSON, SEX_OF_PERSON, PERSON_INVOLVED_TYPE, AIRBAG_DEPLOYMENT,
         PERSON_EJECTED, ROLLOVER_OCCURENCE, FIRE_RELATED_CRASH, region_name, 
         urbancity_name, hour, month_name, light_condition, weather_name, Outcome)

accident.join.filtered
```



## Split the data


```{r}
accident.split = initial_validation_split(accident.join.filtered, prop = c(0.6, 0.2))
train.data = training(accident.split)
valid.data = validation(accident.split)
test.data = testing(accident.split)

train.data
```

## Look at the training data

The outcome variable is imbalanced as majority of crashes do not require hospital transport.
```{r}
ggplot(train.data) +
  aes(x=Outcome) +
  geom_bar() 
```


## Train the data


### Random Forest (RF)

#### RF: Fit the model to the train data
```{r}
rf.model = rand_forest(mode="classification") %>%
  fit(Outcome ~ ., data=train.data)
```

#### RF: Evaluation with the validation data:

```{r}
rf.valid.data = na.omit(valid.data) %>%
  bind_cols(predict(rf.model, na.omit(valid.data))) %>%
  glimpse()
```

#### RF: Apply the metrics:

```{r}
sba_metrics(rf.valid.data, truth=Outcome, estimate=.pred_class)
```
### XGB

#### XGB: Fit the model to the training data
```{r}
xgb.model = boost_tree(mode="classification") %>%
  fit(Outcome ~ ., data=train.data)
```
#### XGB: Evaluation with the validation data:

```{r}
xgb.valid.data = valid.data %>%
  bind_cols(predict(xgb.model, valid.data)) %>%
  glimpse()
```

#### XGB: Apply the metrics:

```{r}
sba_metrics(xgb.valid.data, truth=Outcome, estimate=.pred_class)
```



## Tune the hyperparameters for our selected model XGB

### XGBoost Tuning - tune tree size, mtry, and tree depth
#### XGB - Tune tree size
```{r}
tree_sizes = c(10, 50, 75, 100, 200, 300, 500)
tree_metrics = map_df(tree_sizes, function(n) {
  preds = boost_tree(mode="classification", trees=n) %>%
    fit(Outcome ~ ., data=train.data) %>%
    predict(valid.data)
  results = valid.data %>%
    select(Outcome) %>%
    bind_cols(preds)
  sba_metrics(results, truth = Outcome, estimate = .pred_class) %>%
    mutate(trees=n)
})
```

We can plot:

```{r}
ggplot(tree_metrics %>% filter(.metric == "kap")) +
  aes(x=trees, y=.estimate) +
  geom_line() +
  xlab("Number of Trees") +
  ylab("Cohen's kappa")
```
Let's automatically pick the best tree size.

```{r}
xgb.trees = tree_metrics %>% filter(.metric == "kap") %>%
  slice_max(.estimate, n=1, with_ties=FALSE) %>%
  pull(trees)
xgb.trees
```


#### XGB: Tune number of variables in each tree (mtry)
```{r}
mtry_sizes = c(1,2,3,4,5,6,7,8,9,10,11,12,13)
mtry_metrics = map_df(mtry_sizes, function(n) {
  preds = boost_tree(mode="classification", trees=xgb.trees, mtry=n) %>%
    fit(Outcome ~ ., data=train.data) %>%
    predict(valid.data)
  results = valid.data %>%
    select(Outcome) %>%
    bind_cols(preds)
  sba_metrics(results, truth = Outcome, estimate = .pred_class) %>%
    mutate(mtry=n)
})

```

Plot the values against the Cohen's Kappa value:

```{r}
ggplot(mtry_metrics %>% filter(.metric == "kap")) +
  aes(x=mtry, y=.estimate) +
  geom_line() +
  xlab("Number of Features (mtry)") +
  ylab("Cohen's kappa")
```

Pick the optimum mtry value:

```{r}
xgb.mtry = mtry_metrics %>% filter(.metric == "kap") %>%
  slice_max(.estimate, n=1) %>%
  pull(mtry)
xgb.mtry
```



#### XGB: Tune the maximum tree depth
Used ChatGPT to identify what tree depths to try. Advice was to first try sizes between 3-11. (ChatGPT-2, 2024) This seemed sufficient for our activity.
```{r}
tree.depth.sizes = c(3,4,5,6,7,8,9,10,11)
tree.depth.metrics = map_df(tree.depth.sizes, function(n) {
  preds = boost_tree(mode="classification", trees=xgb.trees, mtry=xgb.mtry, tree_depth=n) %>%
    fit(Outcome ~ ., data=train.data) %>%
    predict(valid.data)
  results = valid.data %>%
    select(Outcome) %>%
    bind_cols(preds)
  sba_metrics(results, truth = Outcome, estimate = .pred_class) %>%
    mutate(tree_depth=n)
})
```

Plot the tree depths against the Cohen's Kappa:
```{r}
ggplot(tree.depth.metrics %>% filter(.metric == "kap")) +
  aes(x=tree_depth, y=.estimate) +
  geom_line() +
  xlab("Tree Depth") +
  ylab("Cohen's kappa")
```



Select the best maximum tree depth value:
```{r}
xgb.tree.depth = tree.depth.metrics %>% filter(.metric == "kap") %>%
  slice_max(.estimate, n=1) %>%
  pull(tree_depth)
xgb.tree.depth
```


#### XGB: Re-fit the train data with optimum values
```{r}
xgb.model = boost_tree(mode="classification", trees=xgb.trees, mtry=xgb.mtry, tree_depth = xgb.tree.depth) %>%
  fit(Outcome ~ ., data=train.data)
```

#### XGB: Re-evaluate against the validation data
```{r}
xgb.valid.data = valid.data %>%
  bind_cols(predict(xgb.model, valid.data))
```

#### XGB: Apply the metrics
```{r}
sba_metrics(xgb.valid.data, truth=Outcome, estimate=.pred_class)
```

## Test the data

# Prepare the test data for evaluation
test_xgb_data <- prepare_xgb_data(test.data)

# Predict on test data
test_pred <- predict(xgb_results$model, test_xgb_data$X)
test_pred_binary <- ifelse(test_pred > 0.5, 1, 0)

# Calculate test metrics
library(MLmetrics)
test_metrics <- list(
  confusion_matrix = table(Predicted = test_pred_binary, Actual = test_xgb_data$y),
  accuracy = mean(test_pred_binary == test_xgb_data$y),
  auc = AUC(y_pred = test_pred, y_true = test_xgb_data$y)
)

# Print the test metrics
print("Confusion Matrix:")
print(test_metrics$confusion_matrix)

print(paste("Accuracy:", round(test_metrics$accuracy, 3)))
print(paste("AUC:", round(test_metrics$auc, 3)))

# Plot the feature importance
feature_importance <- xgb.importance(model = xgb_results$model)

# Visualize feature importance
xgb.plot.importance(importance_matrix = feature_importance)



#### XGB: Re-evaluate against the validation data
```{r}
xgb.test.data = test.data %>%
  bind_cols(predict(xgb.model, test.data)) %>%
  glimpse()
```

#### XGB: Apply the metrics
```{r}
sba_metrics(xgb.test.data, truth=Outcome, estimate=.pred_class)
```


## Evaluate Model/Create Charts




## Outcomes

